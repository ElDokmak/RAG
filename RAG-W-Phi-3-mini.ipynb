{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook is from llama_index, just trying it","metadata":{}},{"cell_type":"code","source":"!pip install llama-index llama-index-llms-huggingface llama-index-embeddings-huggingface transformers accelerate bitsandbytes llama-index-readers-web matplotlib flash-attn","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:45:51.772999Z","iopub.execute_input":"2024-04-28T15:45:51.773368Z","iopub.status.idle":"2024-04-28T15:47:03.859128Z","shell.execute_reply.started":"2024-04-28T15:45:51.773338Z","shell.execute_reply":"2024-04-28T15:47:03.858014Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting llama-index\n  Downloading llama_index-0.10.33-py3-none-any.whl.metadata (11 kB)\nCollecting llama-index-llms-huggingface\n  Downloading llama_index_llms_huggingface-0.1.4-py3-none-any.whl.metadata (741 bytes)\nCollecting llama-index-embeddings-huggingface\n  Downloading llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl.metadata (725 bytes)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nCollecting llama-index-readers-web\n  Downloading llama_index_readers_web-0.1.10-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nCollecting flash-attn\n  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n  Downloading llama_index_agent_openai-0.2.3-py3-none-any.whl.metadata (678 bytes)\nCollecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.11.0,>=0.10.32 (from llama-index)\n  Downloading llama_index_core-0.10.33-py3-none-any.whl.metadata (3.7 kB)\nCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n  Downloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl.metadata (603 bytes)\nCollecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n  Downloading llama_index_llms_openai-0.1.16-py3-none-any.whl.metadata (559 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\nCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\nCollecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n  Downloading llama_index_readers_file-0.1.19-py3-none-any.whl.metadata (979 bytes)\nCollecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\nCollecting huggingface-hub<0.21.0,>=0.20.3 (from llama-index-llms-huggingface)\n  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-huggingface) (2.1.2)\nCollecting sentence-transformers<3.0.0,>=2.6.1 (from llama-index-embeddings-huggingface)\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-web) (3.9.1)\nCollecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-web)\n  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\nCollecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web)\n  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\nCollecting html2text<2021.0.0,>=2020.1.16 (from llama-index-readers-web)\n  Downloading html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\nCollecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web)\n  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\nCollecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n  Downloading playwright-1.43.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\nCollecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web)\n  Downloading selenium-4.20.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: urllib3>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-web) (1.26.18)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nCollecting einops (from flash-attn)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (4.0.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.5)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.9.0)\nRequirement already satisfied: pydantic<3.0,>1.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.3)\nCollecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n  Downloading openai-1.23.6-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.0.25)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.6.4)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.2.14)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.32->llama-index)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.27.0)\nCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.32->llama-index)\n  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.5.8)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.2.1)\nCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.32->llama-index)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2.1.4)\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (8.2.3)\nCollecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.32->llama-index)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.14.1)\nRequirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nCollecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n  Downloading llama_parse-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: lxml>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (5.1.0)\nCollecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\nCollecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\nCollecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading jieba3k-0.35.1.zip (7.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: greenlet==3.0.3 in /opt/conda/lib/python3.10/site-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.0.3)\nCollecting pyee==11.1.0 (from playwright<2.0,>=1.30->llama-index-readers-web)\n  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nCollecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\nCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.11.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.2)\nCollecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (0.14.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.2)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.14.6)\nCollecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n  Downloading requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (2.4.0)\nCollecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.2.0)\nCollecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.0)\nRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.7.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.21.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2023.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\nDownloading llama_index-0.10.33-py3-none-any.whl (6.9 kB)\nDownloading llama_index_llms_huggingface-0.1.4-py3-none-any.whl (7.2 kB)\nDownloading llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl (7.1 kB)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_readers_web-0.1.10-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\nDownloading html2text-2020.1.16-py3-none-any.whl (32 kB)\nDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.2.3-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\nDownloading llama_index_core-0.10.33-py3-none-any.whl (15.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl (6.0 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\nDownloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_llms_openai-0.1.16-py3-none-any.whl (10 kB)\nDownloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\nDownloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\nDownloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.1.19-py3-none-any.whl (36 kB)\nDownloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\nDownloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading playwright-1.43.0-py3-none-manylinux1_x86_64.whl (37.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyee-11.1.0-py3-none-any.whl (15 kB)\nDownloading selenium-4.20.0-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\nDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_parse-0.4.2-py3-none-any.whl (7.6 kB)\nDownloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.23.6-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trio-0.25.0-py3-none-any.whl (467 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\nDownloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\nDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: flash-attn, tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.8-cp310-cp310-linux_x86_64.whl size=120607435 sha256=b962f0eb38a2e54a3ece20b4b43f59f5a638ce53fe6e269992c58b119425d1f0\n  Stored in directory: /root/.cache/pip/wheels/9b/5b/2b/dea8af4e954161c49ef1941938afcd91bb93689371ed12a226\n  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13538 sha256=e62c1ab508e766a61105b164eb14fe433d5c79f5e09959dc02297cb7048604f3\n  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3340 sha256=1aa3ffc0a39b8f3ffea8952df9c21b238cdf0a6f70b9d615616bc397a0f19434\n  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=fb10ae8d85c54bca1d52b15c97b754630d1e1d06f3b17629d5b8e510f6f0c916\n  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=6f83b5ddc0b5f672f8eba587e39ccaab065c8d78c2697ab61c685dd071c218ab\n  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\nSuccessfully built flash-attn tinysegmenter feedfinder2 jieba3k sgmllib3k\nInstalling collected packages: tinysegmenter, striprtf, sgmllib3k, jieba3k, dirtyjson, wsproto, pyee, packaging, outcome, nltk, html2text, feedparser, einops, cssselect, beautifulsoup4, trio, tiktoken, requests-file, playwright, huggingface-hub, feedfinder2, chromedriver-autoinstaller, trio-websocket, tldextract, openai, llamaindex-py-client, flash-attn, bitsandbytes, selenium, newspaper3k, llama-index-legacy, llama-index-core, sentence-transformers, llama-parse, llama-index-readers-web, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-huggingface, llama-index-embeddings-huggingface, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: beautifulsoup4\n    Found existing installation: beautifulsoup4 4.12.2\n    Uninstalling beautifulsoup4-4.12.2:\n      Successfully uninstalled beautifulsoup4-4.12.2\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.21.4\n    Uninstalling huggingface-hub-0.21.4:\n      Successfully uninstalled huggingface-hub-0.21.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed beautifulsoup4-4.12.3 bitsandbytes-0.43.1 chromedriver-autoinstaller-0.6.4 cssselect-1.2.0 dirtyjson-1.0.8 einops-0.8.0 feedfinder2-0.0.4 feedparser-6.0.11 flash-attn-2.5.8 html2text-2020.1.16 huggingface-hub-0.20.3 jieba3k-0.35.1 llama-index-0.10.33 llama-index-agent-openai-0.2.3 llama-index-cli-0.1.12 llama-index-core-0.10.33 llama-index-embeddings-huggingface-0.2.0 llama-index-embeddings-openai-0.1.9 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-huggingface-0.1.4 llama-index-llms-openai-0.1.16 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.19 llama-index-readers-llama-parse-0.1.4 llama-index-readers-web-0.1.10 llama-parse-0.4.2 llamaindex-py-client-0.1.19 newspaper3k-0.2.8 nltk-3.8.1 openai-1.23.6 outcome-1.3.0.post0 packaging-24.0 playwright-1.43.0 pyee-11.1.0 requests-file-2.0.0 selenium-4.20.0 sentence-transformers-2.7.0 sgmllib3k-1.0.0 striprtf-0.0.26 tiktoken-0.6.0 tinysegmenter-0.3 tldextract-5.1.2 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DATA","metadata":{}},{"cell_type":"code","source":"from llama_index.readers.web import BeautifulSoupWebReader\n\nurl = \"https://www.theverge.com/2023/9/29/23895675/ai-bot-social-network-openai-meta-chatbots\"\ndocs = BeautifulSoupWebReader().load_data([url])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:47:07.789546Z","iopub.execute_input":"2024-04-28T15:47:07.790375Z","iopub.status.idle":"2024-04-28T15:47:17.973180Z","shell.execute_reply.started":"2024-04-28T15:47:07.790344Z","shell.execute_reply":"2024-04-28T15:47:17.972372Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### MODEL","metadata":{}},{"cell_type":"code","source":"from llama_index.llms.huggingface import HuggingFaceLLM\n\n\ndef messages_to_prompt(messages):\n    prompt = \"\"\n    system_found = False\n    for message in messages:\n        if message.role == \"system\":\n            prompt += f\"<|system|>\\n{message.content}<|end|>\\n\"\n            system_found = True\n        elif message.role == \"user\":\n            prompt += f\"<|user|>\\n{message.content}<|end|>\\n\"\n        elif message.role == \"assistant\":\n            prompt += f\"<|assistant|>\\n{message.content}<|end|>\\n\"\n        else:\n            prompt += f\"<|user|>\\n{message.content}<|end|>\\n\"\n\n    # trailing prompt\n    prompt += \"<|assistant|>\\n\"\n\n    if not system_found:\n        prompt = (\n            \"<|system|>\\nYou are a helpful AI assistant.<|end|>\\n\" + prompt\n        )\n\n    return prompt\n\n\nllm = HuggingFaceLLM(\n    model_name=\"microsoft/Phi-3-mini-4k-instruct\",\n    model_kwargs={\n        \"trust_remote_code\": True,\n    },\n    generate_kwargs={\"do_sample\": True, \"temperature\": 0.1},\n    tokenizer_name=\"microsoft/Phi-3-mini-4k-instruct\",\n    query_wrapper_prompt=(\n        \"<|system|>\\n\"\n        \"You are a helpful AI assistant.<|end|>\\n\"\n        \"<|user|>\\n\"\n        \"{query_str}<|end|>\\n\"\n        \"<|assistant|>\\n\"\n    ),\n    messages_to_prompt=messages_to_prompt,\n    is_chat_model=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:47:24.299562Z","iopub.execute_input":"2024-04-28T15:47:24.300672Z","iopub.status.idle":"2024-04-28T15:48:17.412041Z","shell.execute_reply.started":"2024-04-28T15:47:24.300615Z","shell.execute_reply":"2024-04-28T15:48:17.411035Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36fa1b007ff4c078bb422a4a00ddb59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf936de3032b4f80802d2b5574f87b30"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9874c595d34e38b6419a82bded9990"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa1fd9dcb2d84fab8b0bd17e5207862d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"077bb311479d4d81a426166c6156284e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c82d077a2cb4b3ba0462429e970a79f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff8bb68751743c8a2bbb64ea1beb126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e162c53ce6c48fa9270703999625b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14b44cf89db484b91f2b9b40e5b3eef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0761fde87ed4c9cb639aa6104cf3269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b73994323c42b0a7be430174c05bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fadd0e468e964c3a89bfdcad4c06c290"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c09f2bb8c72841ab9a786da0f36997a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e4fd3a0be4449e8a25173e710ffa954"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### EMBEDDINGS","metadata":{}},{"cell_type":"code","source":"from llama_index.core import Settings\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\nSettings.llm = llm\nSettings.embed_model = HuggingFaceEmbedding(\n    model_name=\"BAAI/bge-small-en-v1.5\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:48:23.013622Z","iopub.execute_input":"2024-04-28T15:48:23.014618Z","iopub.status.idle":"2024-04-28T15:48:26.066586Z","shell.execute_reply.started":"2024-04-28T15:48:23.014584Z","shell.execute_reply":"2024-04-28T15:48:26.065479Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"065ed85c65f9475d96e037b8b96ce5d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69cbe4be96e4691a22f93a7e46c8727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d70596a2ab8473086da972325b5e940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c37431de854ab2a73c5553e6f1bee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b9de71cd3b4c79b8dd9b8c7fb49cfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e02e58b768442a4875bda877091cdd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a37987b7bd647e69db0a9d07120ee5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682c470335b44bd3ab0275ef4d4fcbd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e598162a5be3450395403d4f34b95a25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdf794c9faf438fa2ba9205e8f55d06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab7cebebaa5438fb95a80c94839df41"}},"metadata":{}}]},{"cell_type":"markdown","source":"### INDEX","metadata":{}},{"cell_type":"code","source":"from llama_index.core import VectorStoreIndex\n\nvector_index = VectorStoreIndex.from_documents(\n    docs\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:56:28.558025Z","iopub.execute_input":"2024-04-28T15:56:28.558883Z","iopub.status.idle":"2024-04-28T15:56:28.651117Z","shell.execute_reply.started":"2024-04-28T15:56:28.558851Z","shell.execute_reply":"2024-04-28T15:56:28.650327Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a930af82fc9a485c8b9bcf351067540c"}},"metadata":{}}]},{"cell_type":"code","source":"from llama_index.core import SummaryIndex\n\nsummary_index = SummaryIndex.from_documents(\n    docs\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:48:42.978565Z","iopub.execute_input":"2024-04-28T15:48:42.979442Z","iopub.status.idle":"2024-04-28T15:48:42.992695Z","shell.execute_reply.started":"2024-04-28T15:48:42.979409Z","shell.execute_reply":"2024-04-28T15:48:42.991701Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.response.notebook_utils import display_response","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:48:57.593215Z","iopub.execute_input":"2024-04-28T15:48:57.593963Z","iopub.status.idle":"2024-04-28T15:48:57.599372Z","shell.execute_reply.started":"2024-04-28T15:48:57.593925Z","shell.execute_reply":"2024-04-28T15:48:57.598448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import logging\nimport sys\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:57:55.339774Z","iopub.execute_input":"2024-04-28T15:57:55.340690Z","iopub.status.idle":"2024-04-28T15:57:55.345784Z","shell.execute_reply.started":"2024-04-28T15:57:55.340657Z","shell.execute_reply":"2024-04-28T15:57:55.344715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### BASIC RAG\n1. compat\n2. refine\n3. tree_summarize","metadata":{}},{"cell_type":"code","source":"query_engine = vector_index.as_query_engine(\n    response_mode = \"compact\"\n)\n\nresponse = query_engine.query(\n    \"How do OpenAI and Meta differ on AI tools?\"\n)\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:49:07.817962Z","iopub.execute_input":"2024-04-28T15:49:07.818834Z","iopub.status.idle":"2024-04-28T15:49:35.342812Z","shell.execute_reply.started":"2024-04-28T15:49:07.818801Z","shell.execute_reply":"2024-04-28T15:49:35.341878Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa32cc1ca04245b3a671d9e0e039949a"}},"metadata":{}},{"name":"stderr","text":"2024-04-28 15:49:13.877743: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 15:49:13.877854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 15:49:14.045436: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** OpenAI and Meta differ in their approach to AI tools. OpenAI tends to present its products as productivity tools, focusing on simple utilities for getting things done. On the other hand, Meta, which is in the entertainment business, has developed its own uses for generative AI and voices, creating personality-driven chatbots for its messaging apps. While OpenAI's ChatGPT is a versatile AI assistant, Meta's AI characters are designed to interact with users in a more personalized and entertaining manner."},"metadata":{}}]},{"cell_type":"code","source":"query_engine = vector_index.as_query_engine(\n    response_mode = \"refine\"\n)\n\nresponse = query_engine.query(\n    \"How do OpenAI and Meta differ on AI tools?\"\n)\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:50:44.638017Z","iopub.execute_input":"2024-04-28T15:50:44.638946Z","iopub.status.idle":"2024-04-28T15:51:07.791289Z","shell.execute_reply.started":"2024-04-28T15:50:44.638911Z","shell.execute_reply":"2024-04-28T15:51:07.790275Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ada574eff2fd4b28b9a47823e50c1db1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** OpenAI and Meta have distinct approaches to their AI tools. OpenAI primarily emphasizes the productivity aspect, showcasing their AI as straightforward utilities designed to help users complete tasks efficiently. Conversely, Meta, although also involved in AI development, leans towards the entertainment sector. They have introduced personality-driven chatbots for their messaging platforms, with a diverse range of celebrities lending their voices to these bots. This divergence in focus highlights the versatility and potential applications of AI technology across different industries."},"metadata":{}}]},{"cell_type":"code","source":"query_engine = vector_index.as_query_engine(\n    response_mode = \"tree_summarize\"\n)\n\nresponse = query_engine.query(\n    \"How do OpenAI and Meta differ on AI tools?\"\n)\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:51:13.912927Z","iopub.execute_input":"2024-04-28T15:51:13.914130Z","iopub.status.idle":"2024-04-28T15:51:40.725595Z","shell.execute_reply.started":"2024-04-28T15:51:13.914065Z","shell.execute_reply":"2024-04-28T15:51:40.724369Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3845c994a56144ae859f5c59e8f8107a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** OpenAI and Meta differ in their approach and application of AI tools. OpenAI tends to present its products as productivity tools, focusing on simple utilities designed to help users accomplish tasks efficiently. Their AI tool, ChatGPT, is an example of this, providing users with a large language model that can generate human-like text responses, assist with various tasks, and even interact via voice.\n\nOn the other hand, Meta (formerly Facebook) is in the entertainment business and has developed its own uses for generative AI and voices. They have created 28 personality-driven chatbots for their messaging apps, with celebrities lending their voices to these AI characters. These chatbots are designed to engage users in a more personalized and entertaining manner, rather than focusing solely on productivity.\n\nIn summary, OpenAI emphasizes productivity and utility in their AI tools, while Meta focuses on entertainment and personalized interactions through their AI-driven chatbots."},"metadata":{}}]},{"cell_type":"markdown","source":"### ROUTER QUERY ENGINE\n1. single selector\n2. multi selector","metadata":{}},{"cell_type":"code","source":"from llama_index.core.tools import QueryEngineTool, ToolMetadata\n\nvector_tool = QueryEngineTool(\n    vector_index.as_query_engine(),\n    metadata=ToolMetadata(\n        name=\"vector_search\",\n        description=\"Useful for searching for specific facts.\",\n    ),\n)\n\nsummary_tool = QueryEngineTool(\n    summary_index.as_query_engine(response_mode=\"tree_summarize\"),\n    metadata=ToolMetadata(\n        name=\"summary\",\n        description=\"Useful for summarizing an entire document.\",\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:56:33.789021Z","iopub.execute_input":"2024-04-28T15:56:33.789802Z","iopub.status.idle":"2024-04-28T15:56:33.796384Z","shell.execute_reply.started":"2024-04-28T15:56:33.789767Z","shell.execute_reply":"2024-04-28T15:56:33.795251Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.query_engine import RouterQueryEngine\n\nquery_engine = RouterQueryEngine.from_defaults(\n    [vector_tool, summary_tool], select_multi=False\n)\n\nresponse = query_engine.query(\"What was mentioned about Meta?\")\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:56:45.421736Z","iopub.execute_input":"2024-04-28T15:56:45.422355Z","iopub.status.idle":"2024-04-28T15:57:12.582675Z","shell.execute_reply.started":"2024-04-28T15:56:45.422322Z","shell.execute_reply":"2024-04-28T15:57:12.581648Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9495646f41804761a8636443bc922a8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** 1. Meta is in the entertainment business, not just the tech industry.\n2. Meta has found its own uses for generative AI and voices.\n3. Meta unveiled 28 personality-driven chatbots to be used in Meta's messaging apps.\n4. Celebrities including Charli D'Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lent their voices to Meta's chatbots.\n5. Meta's chatbots have brief and often humorous character descriptions, such as MrBeast's characterization as \"the big brother who will roast you.\""},"metadata":{}}]},{"cell_type":"code","source":"from llama_index.core.query_engine import RouterQueryEngine\n\nquery_engine = RouterQueryEngine.from_defaults(\n    [vector_tool, summary_tool],\n    select_multi=True,\n)\n\nresponse = query_engine.query(\n    \"What was mentioned about Meta? Summarize with any other companies mentioned in the entire document.\"\n)\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:58:15.858856Z","iopub.execute_input":"2024-04-28T15:58:15.859743Z","iopub.status.idle":"2024-04-28T15:58:50.004285Z","shell.execute_reply.started":"2024-04-28T15:58:15.859711Z","shell.execute_reply":"2024-04-28T15:58:50.003284Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Selecting query engine 1: Useful for summarizing an entire document, which is needed to provide a summary about Meta and other companies mentioned in the document..\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** Meta, a company in the entertainment business, is developing its own uses for generative AI and voices, as revealed on Wednesday. They unveiled 28 personality-driven chatbots to be used in Meta's messaging apps, with celebrity voices including Charli D'Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton. These chatbots come with brief and often cringeworthy descriptions, and are seen as an intermediate step towards a synthetic social network. Meta plans to place its AI characters on every major surface of its products, potentially transforming feeds from human-defined connections to partially synthetic social networks.\n\nIn addition to Meta, OpenAI, another tech company, is also developing AI tools. OpenAI presents its products as productivity tools, while Meta is focusing on entertainment. OpenAI's ChatGPT, a large language model, has evolved to become more useful and versatile, with the addition of a voice feature that could potentially lead to a more empathetic and patient AI companion. Both companies"},"metadata":{}}]},{"cell_type":"markdown","source":"### SUBQUESTION QUERY ENGINE","metadata":{}},{"cell_type":"code","source":"from llama_index.core.tools import QueryEngineTool, ToolMetadata\n\nvector_tool = QueryEngineTool(\n    vector_index.as_query_engine(),\n    metadata=ToolMetadata(\n        name=\"vector_search\",\n        description=\"Useful for searching for specific facts.\",\n    ),\n)\n\nsummary_tool = QueryEngineTool(\n    summary_index.as_query_engine(response_mode=\"tree_summarize\"),\n    metadata=ToolMetadata(\n        name=\"summary\",\n        description=\"Useful for summarizing an entire document.\",\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:59:17.374791Z","iopub.execute_input":"2024-04-28T15:59:17.375195Z","iopub.status.idle":"2024-04-28T15:59:17.381640Z","shell.execute_reply.started":"2024-04-28T15:59:17.375165Z","shell.execute_reply":"2024-04-28T15:59:17.380575Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import nest_asyncio\n\nnest_asyncio.apply()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:59:21.380024Z","iopub.execute_input":"2024-04-28T15:59:21.380847Z","iopub.status.idle":"2024-04-28T15:59:21.386281Z","shell.execute_reply.started":"2024-04-28T15:59:21.380819Z","shell.execute_reply":"2024-04-28T15:59:21.385078Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.query_engine import SubQuestionQueryEngine\n\nquery_engine = SubQuestionQueryEngine.from_defaults(\n    [vector_tool, summary_tool],\n    verbose=True,\n)\n\nresponse = query_engine.query(\n    \"What was mentioned about Meta? How Does it differ from how OpenAI is talked about?\"\n)\n\ndisplay_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:59:38.959387Z","iopub.execute_input":"2024-04-28T15:59:38.960060Z","iopub.status.idle":"2024-04-28T16:01:32.972600Z","shell.execute_reply.started":"2024-04-28T15:59:38.960028Z","shell.execute_reply":"2024-04-28T16:01:32.971563Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Generated 3 sub questions.\n\u001b[1;3;38;2;237;90;200m[vector_search] Q: What are the key points mentioned about Meta in documents?\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c8ec6599f0d4d97b4dd5981dccbf9a4"}},"metadata":{}},{"name":"stdout","text":"\u001b[1;3;38;2;237;90;200m[vector_search] A: 1. Meta is in the entertainment business, not just a productivity tool like OpenAI.\n2. Meta has built its own uses for generative AI and voices.\n3. Meta unveiled 28 personality-driven chatbots for its messaging apps.\n4. Celebrities like Charli D'Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Tom Brady, and Paris Hilton lent their voices to these chatbots.\n5. Each celebrity character has a brief and often humorous description, such as MrBeast's characterization as \"the big brother who will roast you.\"\n6. It's suggested that celebrities may not yet be willing to entrust their entire personas to Meta, but offering people a taste of interacting with AI Snoop Dogg could help iron out any issues before the full launch.\n7. The introduction of these chatbots could potentially mark the beginning of a new era in social networking, where AI characters become a significant part of the user experience.\n\u001b[0m\u001b[1;3;38;2;90;149;237m[vector_search] Q: What are the key points mentioned about OpenAI in documents?\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"925f7d329f4f4c998ca64984608c90fd"}},"metadata":{}},{"name":"stdout","text":"\u001b[1;3;38;2;90;149;237m[vector_search] A: 1. OpenAI announced the latest updates for ChatGPT, which now includes voice interaction and image uploading capabilities.\n2. The addition of a voice feature to ChatGPT gives it a hint of personality, making it more powerful as a mobile app and potentially more empathetic and helpful.\n3. OpenAI presents its products as productivity tools, but the development of generative AI and voices shows its interest in the entertainment industry.\n4. OpenAI has created 28 personality-driven chatbots for use in Meta's messaging apps, with celebrity voices lending their personalities to these AI characters.\n5. The voice feature is currently available to ChatGPT Plus subscribers, with free users expected to gain access in the future.\n6. The potential for AI to become a synthetic social network is discussed, with the implications of a more personalized, engaging, and entertaining social media experience.\n7. The development of AI in social networking raises questions about the range of views on the experience, whether it will feel more personalized, engaging, and entertaining, or uncanny, hollow, and junky\n\u001b[0m\u001b[1;3;38;2;11;159;203m[summary] Q: How does Meta differ from OpenAI in terms of their mentioned attributes or achievements?\n\u001b[0m\u001b[1;3;38;2;11;159;203m[summary] A: Meta and OpenAI differ in their approach and applications of AI technology. OpenAI primarily presents its products as productivity tools, focusing on simple utilities for getting things done, such as the ChatGPT AI that can provide pep talks, voice memos, and daily affirmations about identity issues. On the other hand, Meta, while also developing LLMs, is in the entertainment business and has created 28 personality-driven chatbots for its messaging apps, with celebrity voices like Charli D'Amelio, Dwyane Wade, and others. Meta's chatbots are designed to offer a more personalized and entertaining experience, potentially leading to a partially synthetic social network. While OpenAI's ChatGPT is more focused on productivity and utility, Meta's chatbots aim to provide a more engaging and entertaining interaction, blending AI with celebrity personas.\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** 1. Meta is involved in the entertainment industry, creating personality-driven chatbots for messaging apps.\n2. Celebrities have lent their voices to Meta's chatbots, offering users a unique and engaging experience.\n3. Meta's chatbots could potentially lead to a new era in social networking, with AI characters becoming a significant part of the user experience.\n4. The development of Meta's chatbots is seen as a step towards a partially synthetic social network.\n\nIn contrast, OpenAI is primarily focused on productivity tools, with its ChatGPT AI offering utilities like pep talks and voice memos. While OpenAI also develops generative AI and voices, its applications are more centered around utility rather than entertainment. The key difference lies in Meta's emphasis on creating an engaging and entertaining social networking experience through celebrity-driven AI chatbots, while OpenAI's ChatGPT is geared towards productivity and utility."},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}